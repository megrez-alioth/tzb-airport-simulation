#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ZGGGæœºåœºç§¯å‹æ—¶æ®µåˆ†æ
ä¸“é—¨åˆ†æçœŸå®èˆªç­æ•°æ®ï¼Œæ¢ç´¢åˆç†çš„å»¶è¯¯åˆ¤å®šæ ‡å‡†
é¿å…å…¨å¤©éƒ½æ˜¯ç§¯å‹æ—¶æ®µçš„ç°è±¡
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

class ZGGGBacklogAnalyzer:
    def __init__(self):
        """åˆå§‹åŒ–ç§¯å‹åˆ†æå™¨"""
        self.data = None
        self.backlog_threshold = 10  # ç§¯å‹åˆ¤å®šé˜ˆå€¼ï¼šå»¶è¯¯èˆªç­æ•°>=10
        
        print("=== ZGGGæœºåœºç§¯å‹æ—¶æ®µåˆ†æå™¨ ===")
        print(f"ç§¯å‹åˆ¤å®šæ ‡å‡†: å»¶è¯¯èˆªç­æ•° >= {self.backlog_threshold} ç­/å°æ—¶")
        print("æ–°å¢åŠŸèƒ½: ç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µè¯†åˆ«ä¸è¿‡æ»¤")
    
    def identify_weather_suspension_periods(self, data):
        """è¯†åˆ«å¤©æ°”åœé£æ—¶æ®µ"""
        print(f"\n=== è¯†åˆ«å¤©æ°”åœé£æ—¶æ®µ ===")
        
        # æŒ‰æ—¥æœŸåˆ†ç»„ï¼Œå¯»æ‰¾åœé£æ—¶æ®µ
        weather_periods = []
        
        for date in data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date.unique():
            day_data = data[data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date == date].copy()
            day_data = day_data.sort_values('è®¡åˆ’ç¦»æ¸¯æ—¶é—´')
            
            # å¯»æ‰¾è¿ç»­çš„é•¿æ—¶é—´å»¶è¯¯æˆ–åœé£
            # æ”¹è¿›æ ‡å‡†ï¼šéœ€è¦è¶³å¤Ÿçš„èˆªç­æ ·æœ¬æ‰èƒ½åˆ¤å®šä¸ºç³»ç»Ÿæ€§åœé£
            for hour in range(24):
                hour_data = day_data[day_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour == hour]
                if len(hour_data) == 0:
                    continue
                
                # æ£€æŸ¥è¯¥å°æ—¶æ˜¯å¦æœ‰å¼‚å¸¸çš„é•¿å»¶è¯¯
                if 'å®é™…èµ·é£æ—¶é—´' in hour_data.columns:
                    delays = (
                        hour_data['å®é™…èµ·é£æ—¶é—´'] - hour_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´']
                    ).dt.total_seconds() / 60
                    
                    # æ”¹è¿›çš„å¤©æ°”åœé£åˆ¤å®šæ¡ä»¶
                    severe_delays = (delays > 120).sum()
                    
                    # æ–°çš„æ¡ä»¶ï¼šè‡³å°‘éœ€è¦3ç­èˆªç­ï¼Œä¸”80%ä»¥ä¸Šä¸¥é‡å»¶è¯¯æ‰è®¤ä¸ºæ˜¯ç³»ç»Ÿæ€§åœé£
                    if (len(hour_data) >= 3 and  # è‡³å°‘3ç­èˆªç­
                        severe_delays / len(hour_data) > 0.8):  # 80%ä»¥ä¸Šä¸¥é‡å»¶è¯¯
                        
                        # å¯»æ‰¾åœé£æ—¶æ®µçš„å¼€å§‹å’Œç»“æŸ
                        suspend_start = hour_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].min()
                        
                        # ä¼°è®¡åœé£ç»“æŸæ—¶é—´ï¼šæ‰¾åˆ°å»¶è¯¯æ¢å¤æ­£å¸¸çš„æ—¶é—´ç‚¹
                        normal_delay_threshold = 60  # å»¶è¯¯å°äº60åˆ†é’Ÿè®¤ä¸ºæ¢å¤æ­£å¸¸
                        
                        # å‘åæŸ¥æ‰¾ï¼Œç›´åˆ°æ‰¾åˆ°å»¶è¯¯æ¢å¤æ­£å¸¸çš„æ—¶é—´ç‚¹
                        suspend_end = None
                        for check_hour in range(hour, 24):
                            check_data = day_data[day_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour == check_hour]
                            if len(check_data) > 0:
                                check_delays = (
                                    check_data['å®é™…èµ·é£æ—¶é—´'] - check_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´']
                                ).dt.total_seconds() / 60
                                normal_flights = (check_delays <= normal_delay_threshold).sum()
                                
                                if len(check_data) > 0 and normal_flights / len(check_data) > 0.5:
                                    suspend_end = check_data['å®é™…èµ·é£æ—¶é—´'].min()
                                    break
                        
                        if suspend_end is None:
                            # å¦‚æœæ‰¾ä¸åˆ°æ¢å¤æ—¶é—´ï¼Œä½¿ç”¨å½“å¤©æœ€åä¸€ç­å»¶è¯¯èˆªç­çš„èµ·é£æ—¶é—´
                            suspend_end = hour_data['å®é™…èµ·é£æ—¶é—´'].max()
                        
                        weather_periods.append({
                            'date': date,
                            'suspend_start': suspend_start,
                            'suspend_end': suspend_end,
                            'affected_flights': len(hour_data)
                        })
                        
                        print(f"å‘ç°å¤©æ°”åœé£: {date} {suspend_start.strftime('%H:%M')}-{suspend_end.strftime('%H:%M')} å½±å“{len(hour_data)}ç­")
                    elif severe_delays > 0:
                        # è®°å½•è¢«è·³è¿‡çš„æ½œåœ¨ä¸ªåˆ«å»¶è¯¯æƒ…å†µ
                        print(f"è·³è¿‡ä¸ªåˆ«å»¶è¯¯: {date} {hour:02d}:00æ—¶æ®µ - èˆªç­æ•°{len(hour_data)}ç­ï¼Œä¸¥é‡å»¶è¯¯{severe_delays}ç­ (å¯èƒ½æ˜¯ä¸ªåˆ«æƒ…å†µ)")
        
        print(f"è¯†åˆ«åˆ° {len(weather_periods)} ä¸ªå¤©æ°”åœé£æ—¶æ®µ")
        return weather_periods
    
    def identify_exceptional_delays(self, data):
        """è¯†åˆ«å¹¶æ ‡è®°ç‰¹æ®Šå»¶è¯¯èˆªç­ï¼ˆä¸ªåˆ«æƒ…å†µï¼‰ï¼Œè¿™äº›èˆªç­ä¸åº”è®¡å…¥ç§¯å‹åˆ†æ"""
        print(f"\n=== è¯†åˆ«ç‰¹æ®Šå»¶è¯¯èˆªç­ ===")
        
        exceptional_flights = []
        
        # æŒ‰æ—¥æœŸå’Œå°æ—¶åˆ†ç»„åˆ†æ
        for date in data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date.unique():
            day_data = data[data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date == date].copy()
            
            for hour in range(24):
                hour_data = day_data[day_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour == hour]
                if len(hour_data) <= 1:  # åªæœ‰1ç­æˆ–æ›´å°‘ï¼Œè·³è¿‡
                    continue
                
                if 'å®é™…èµ·é£æ—¶é—´' in hour_data.columns:
                    delays = (
                        hour_data['å®é™…èµ·é£æ—¶é—´'] - hour_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´']
                    ).dt.total_seconds() / 60
                    
                    # è®¡ç®—è¯¥æ—¶æ®µçš„å»¶è¯¯åˆ†å¸ƒ
                    normal_delays = (delays <= 60).sum()  # æ­£å¸¸å»¶è¯¯ï¼ˆ<=60åˆ†é’Ÿï¼‰
                    severe_delays = (delays > 120).sum()  # ä¸¥é‡å»¶è¯¯ï¼ˆ>120åˆ†é’Ÿï¼‰
                    
                    # å¦‚æœåªæœ‰å°‘æ•°èˆªç­ä¸¥é‡å»¶è¯¯ï¼Œè€Œå¤§å¤šæ•°æ­£å¸¸ï¼Œåˆ™è®¤ä¸ºæ˜¯ä¸ªåˆ«æƒ…å†µ
                    if (len(hour_data) >= 3 and  # è‡³å°‘3ç­èˆªç­
                        severe_delays <= 2 and  # ä¸¥é‡å»¶è¯¯ä¸è¶…è¿‡2ç­
                        normal_delays / len(hour_data) > 0.6):  # 60%ä»¥ä¸Šèˆªç­å»¶è¯¯æ­£å¸¸
                        
                        # æ‰¾å‡ºä¸¥é‡å»¶è¯¯çš„èˆªç­
                        severe_delay_flights = hour_data[delays > 120]
                        for idx in severe_delay_flights.index:
                            flight_delay = delays[idx]
                            exceptional_flights.append({
                                'index': idx,
                                'date': date,
                                'hour': hour,
                                'delay_minutes': flight_delay,
                                'reason': 'ä¸ªåˆ«ä¸¥é‡å»¶è¯¯'
                            })
                            print(f"æ ‡è®°ç‰¹æ®Šå»¶è¯¯: {date} {hour:02d}:00æ—¶æ®µ - å»¶è¯¯{flight_delay:.0f}åˆ†é’Ÿ (ä¸ªåˆ«æƒ…å†µ)")
        
        print(f"è¯†åˆ«åˆ° {len(exceptional_flights)} ä¸ªç‰¹æ®Šå»¶è¯¯èˆªç­ï¼Œå°†ä»ç§¯å‹åˆ†æä¸­æ’é™¤")
        return exceptional_flights
    
    def identify_systematic_problematic_hours(self, data):
        """è¯†åˆ«ç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µï¼ˆæ•´ä¸ªå°æ—¶æ®µéƒ½æœ‰å¼‚å¸¸å»¶è¯¯ï¼‰"""
        print(f"\n=== è¯†åˆ«ç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µ ===")
        
        problematic_hours = []
        
        # åˆ†ææ¯ä¸ªå°æ—¶çš„æ•´ä½“å»¶è¯¯æƒ…å†µ
        for hour in range(24):
            hour_data = data[data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour == hour]
            if len(hour_data) < 5:  # æ ·æœ¬å¤ªå°‘ï¼Œè·³è¿‡ï¼ˆé™ä½æœ€å°æ ·æœ¬è¦æ±‚ï¼‰
                continue
                
            if 'èµ·é£å»¶è¯¯åˆ†é’Ÿ' in hour_data.columns:
                delays = hour_data['èµ·é£å»¶è¯¯åˆ†é’Ÿ']
                
                avg_delay = delays.mean()
                severe_delay_ratio = (delays > 120).sum() / len(delays) if len(delays) > 0 else 0
                
                # ç³»ç»Ÿæ€§é—®é¢˜çš„åˆ¤å®šæ¡ä»¶ï¼ˆé’ˆå¯¹ä¸åŒæ—¶æ®µé‡‡ç”¨ä¸åŒæ ‡å‡†ï¼‰ï¼š
                is_problematic = False
                
                if 0 <= hour <= 6:  # å‡Œæ™¨æ—¶æ®µï¼ˆ0-6ç‚¹ï¼‰æ›´ä¸¥æ ¼çš„å¼‚å¸¸åˆ¤å®š
                    # å‡Œæ™¨æ—¶æ®µèˆªç­å°‘ï¼Œä½†å¦‚æœå¹³å‡å»¶è¯¯è¶…è¿‡100åˆ†é’Ÿå°±ä¸æ­£å¸¸
                    if ((avg_delay > 100 and severe_delay_ratio > 0.2) or  # å¹³å‡å»¶è¯¯>100åˆ†é’Ÿä¸”20%ä¸¥é‡å»¶è¯¯
                        (avg_delay > 200) or  # æˆ–å¹³å‡å»¶è¯¯>200åˆ†é’Ÿ
                        (severe_delay_ratio > 0.4)):  # æˆ–ä¸¥é‡å»¶è¯¯æ¯”ä¾‹>40%
                        is_problematic = True
                        
                else:  # å…¶ä»–æ—¶æ®µï¼ˆ7-23ç‚¹ï¼‰çš„åˆ¤å®šæ ‡å‡†
                    if (avg_delay > 200 and 
                        severe_delay_ratio > 0.5 and 
                        len(hour_data) >= 10):
                        is_problematic = True
                
                if is_problematic:
                    problematic_hours.append({
                        'hour': hour,
                        'avg_delay': avg_delay,
                        'severe_ratio': severe_delay_ratio,
                        'total_flights': len(hour_data)
                    })
                    
                    print(f"è¯†åˆ«ç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µ: {hour:02d}:00 - å¹³å‡å»¶è¯¯{avg_delay:.0f}åˆ†é’Ÿ, "
                          f"ä¸¥é‡å»¶è¯¯æ¯”ä¾‹{severe_delay_ratio:.1%}, æ€»èˆªç­{len(hour_data)}ç­")
        
        return problematic_hours
    
    def identify_congestion_periods_advanced(self, threshold=15):
        """é«˜çº§ç§¯å‹æ—¶æ®µè¯†åˆ«ï¼Œæ’é™¤å¤©æ°”åœé£ã€ç‰¹æ®Šå»¶è¯¯å’Œç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µ"""
        print(f"\n=== é«˜çº§ç§¯å‹æ—¶æ®µåˆ†æï¼ˆæ’é™¤ç‰¹æ®Šæƒ…å†µï¼‰===")
        
        data = self.data.copy()
        
        # é¦–å…ˆè¯†åˆ«å¤©æ°”åœé£æ—¶æ®µ
        weather_periods = self.identify_weather_suspension_periods(data)
        
        # è¯†åˆ«ç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µ
        problematic_hours = self.identify_systematic_problematic_hours(data)
        
        # æ’é™¤ç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µçš„æ•°æ®
        filtered_data = data.copy()
        if problematic_hours:
            problematic_hour_list = [h['hour'] for h in problematic_hours]
            original_count = len(filtered_data)
            filtered_data = filtered_data[~filtered_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour.isin(problematic_hour_list)]
            excluded_count = original_count - len(filtered_data)
            print(f"æ’é™¤ç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µæ•°æ®: {excluded_count} ä¸ªèˆªç­")
        
        # è¯†åˆ«ç‰¹æ®Šå»¶è¯¯èˆªç­ï¼ˆåœ¨å‰©ä½™æ•°æ®ä¸­ï¼‰
        exceptional_flights = self.identify_exceptional_delays(filtered_data)
        exceptional_indices = {flight['index'] for flight in exceptional_flights}
        
        # æ’é™¤ç‰¹æ®Šå»¶è¯¯èˆªç­
        if exceptional_indices:
            exceptional_indices = exceptional_indices.intersection(filtered_data.index)
            if exceptional_indices:
                filtered_data = filtered_data.drop(exceptional_indices)
                print(f"æ’é™¤ç‰¹æ®Šå»¶è¯¯èˆªç­: {len(exceptional_indices)} ä¸ªèˆªç­")
        
        # æ’é™¤å¤©æ°”åœé£æœŸé—´çš„èˆªç­
        weather_excluded_count = 0
        for weather in weather_periods:
            weather_mask = (
                (filtered_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date == weather['date']) &
                (filtered_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'] >= weather['suspend_start']) &
                (filtered_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'] <= weather['suspend_end'])
            )
            weather_excluded_count += weather_mask.sum()
            filtered_data = filtered_data[~weather_mask]
        
        print(f"æ’é™¤å¤©æ°”åœé£æœŸé—´ {weather_excluded_count} ä¸ªèˆªç­")
        print(f"ç”¨äºç§¯å‹åˆ†æçš„æœ‰æ•ˆèˆªç­æ•°: {len(filtered_data)}")
        
        # åœ¨è¿‡æ»¤åçš„æ•°æ®ä¸Šè¿›è¡Œç§¯å‹åˆ†æ
        filtered_data['å°æ—¶'] = filtered_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour
        filtered_data['æ—¥æœŸ'] = filtered_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date
        filtered_data['å»¶è¯¯æ ‡è®°'] = filtered_data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] > threshold
        
        # æŒ‰å°æ—¶ç»Ÿè®¡å»¶è¯¯æƒ…å†µ
        hourly_stats = filtered_data.groupby(['æ—¥æœŸ', 'å°æ—¶']).agg({
            'å»¶è¯¯æ ‡è®°': ['count', 'sum'],
            'èµ·é£å»¶è¯¯åˆ†é’Ÿ': 'mean'
        }).round(2)
        
        hourly_stats.columns = ['èˆªç­æ•°', 'å»¶è¯¯èˆªç­æ•°', 'å¹³å‡å»¶è¯¯']
        hourly_stats = hourly_stats.reset_index()
        
        # è¯†åˆ«ç§¯å‹æ—¶æ®µ - ä½¿ç”¨åŠ¨æ€é˜ˆå€¼
        total_days = len(filtered_data['æ—¥æœŸ'].unique())
        dynamic_threshold = max(2, self.backlog_threshold / total_days)  # è‡³å°‘2ç­å»¶è¯¯
        
        backlog_periods = hourly_stats[
            hourly_stats['å»¶è¯¯èˆªç­æ•°'] >= dynamic_threshold
        ]
        
        print(f"\nç§¯å‹è¯†åˆ«ç»“æœï¼ˆåŠ¨æ€é˜ˆå€¼: {dynamic_threshold:.1f}ç­/å°æ—¶ï¼‰:")
        print(f"è¯†åˆ«åˆ° {len(backlog_periods)} ä¸ªç§¯å‹æ—¶æ®µ")
        
        if len(backlog_periods) > 0:
            backlog_summary = backlog_periods.groupby('å°æ—¶').agg({
                'å»¶è¯¯èˆªç­æ•°': ['count', 'mean', 'sum']
            }).round(1)
            backlog_summary.columns = ['å‡ºç°å¤©æ•°', 'æ—¥å‡å»¶è¯¯ç­æ•°', 'æ€»å»¶è¯¯ç­æ•°']
            
            print("\nç§¯å‹æ—¶æ®µåˆ†å¸ƒ:")
            print("æ—¶æ®µ    å‡ºç°å¤©æ•°  æ—¥å‡å»¶è¯¯ç­æ•°  æ€»å»¶è¯¯ç­æ•°")
            print("-" * 40)
            for hour in sorted(backlog_summary.index):
                stats = backlog_summary.loc[hour]
                print(f"{hour:02d}:00  {stats['å‡ºç°å¤©æ•°']:6.0f}    {stats['æ—¥å‡å»¶è¯¯ç­æ•°']:8.1f}    {stats['æ€»å»¶è¯¯ç­æ•°']:8.0f}")
        
        return {
            'filtered_data': filtered_data,
            'backlog_periods': backlog_periods,
            'weather_periods': weather_periods,
            'exceptional_flights': exceptional_flights,
            'problematic_hours': problematic_hours,
            'threshold': threshold,
            'dynamic_threshold': dynamic_threshold
        }
    
    def analyze_daily_congestion_patterns(self, threshold=20):
        """æ¯æ—¥ç§¯å‹æ¨¡å¼åˆ†æ"""
        print(f"\n=== æ¯æ—¥ç§¯å‹æ¨¡å¼åˆ†æï¼ˆå»¶è¯¯é˜ˆå€¼: {threshold}åˆ†é’Ÿï¼‰===")
        
        data = self.data.copy()
        data['å°æ—¶'] = data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour
        data['æ—¥æœŸ'] = data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date
        data['å»¶è¯¯æ ‡è®°'] = data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] > threshold
        
        # æŒ‰æ—¥æœŸå’Œå°æ—¶ç»Ÿè®¡
        daily_hourly_stats = data.groupby(['æ—¥æœŸ', 'å°æ—¶']).agg({
            'å»¶è¯¯æ ‡è®°': ['count', 'sum'],
            'èµ·é£å»¶è¯¯åˆ†é’Ÿ': 'mean'
        }).round(2)
        
        daily_hourly_stats.columns = ['èˆªç­æ•°', 'å»¶è¯¯èˆªç­æ•°', 'å¹³å‡å»¶è¯¯']
        daily_hourly_stats = daily_hourly_stats.reset_index()
        
        # è¯†åˆ«æ¯æ—¥çš„ç§¯å‹æ—¶æ®µ
        daily_backlog_summary = []
        total_days = len(data['æ—¥æœŸ'].unique())
        
        print(f"åˆ†æ {total_days} å¤©çš„æ•°æ®...")
        print("\næ¯æ—¥ç§¯å‹æ—¶æ®µè¯†åˆ«:")
        print("æ—¥æœŸ        ç§¯å‹æ—¶æ®µ                     ç§¯å‹èˆªç­æ•°")
        print("-" * 55)
        
        for date in sorted(data['æ—¥æœŸ'].unique()):
            day_data = daily_hourly_stats[daily_hourly_stats['æ—¥æœŸ'] == date]
            day_backlog = day_data[day_data['å»¶è¯¯èˆªç­æ•°'] >= self.backlog_threshold]
            
            if len(day_backlog) > 0:
                backlog_hours = sorted(day_backlog['å°æ—¶'].tolist())
                total_backlog_flights = day_backlog['å»¶è¯¯èˆªç­æ•°'].sum()
                
                # æ ¼å¼åŒ–ç§¯å‹æ—¶æ®µæ˜¾ç¤º
                if len(backlog_hours) == 1:
                    hours_str = f"{backlog_hours[0]:02d}:00"
                elif len(backlog_hours) <= 3:
                    hours_str = ", ".join([f"{h:02d}:00" for h in backlog_hours])
                else:
                    hours_str = f"{backlog_hours[0]:02d}:00-{backlog_hours[-1]:02d}:00ç­‰{len(backlog_hours)}ä¸ªæ—¶æ®µ"
                
                print(f"{date}  {hours_str:<25}  {total_backlog_flights:>8}ç­")
                
                daily_backlog_summary.append({
                    'date': date,
                    'backlog_hours': backlog_hours,
                    'backlog_periods': len(backlog_hours),
                    'total_backlog_flights': total_backlog_flights
                })
            else:
                print(f"{date}  æ— ç§¯å‹æ—¶æ®µ                    {'0':>8}ç­")
        
        # ç»Ÿè®¡åˆ†æ
        if daily_backlog_summary:
            avg_backlog_periods = np.mean([d['backlog_periods'] for d in daily_backlog_summary])
            avg_backlog_flights = np.mean([d['total_backlog_flights'] for d in daily_backlog_summary])
            backlog_days = len(daily_backlog_summary)
            
            print(f"\n=== æ¯æ—¥ç§¯å‹ç»Ÿè®¡ ===")
            print(f"æœ‰ç§¯å‹çš„å¤©æ•°: {backlog_days}/{total_days} å¤© ({backlog_days/total_days*100:.1f}%)")
            print(f"å¹³å‡æ¯å¤©ç§¯å‹æ—¶æ®µæ•°: {avg_backlog_periods:.1f} ä¸ª")
            print(f"å¹³å‡æ¯å¤©ç§¯å‹èˆªç­æ•°: {avg_backlog_flights:.1f} ç­")
            
            # åˆ†æç§¯å‹æ—¶æ®µçš„æ—¶é—´åˆ†å¸ƒ
            all_backlog_hours = []
            for summary in daily_backlog_summary:
                all_backlog_hours.extend(summary['backlog_hours'])
            
            from collections import Counter
            hour_frequency = Counter(all_backlog_hours)
            
            print(f"\nç§¯å‹æ—¶æ®µé¢‘ç‡åˆ†æ:")
            print("æ—¶æ®µ    å‡ºç°æ¬¡æ•°  å ç§¯å‹å¤©æ•°æ¯”ä¾‹")
            print("-" * 30)
            for hour in sorted(hour_frequency.keys()):
                frequency = hour_frequency[hour]
                percentage = frequency / backlog_days * 100
                print(f"{hour:02d}:00   {frequency:6d}      {percentage:6.1f}%")
        else:
            print(f"\n=== æ¯æ—¥ç§¯å‹ç»Ÿè®¡ ===")
            print("åˆ†ææœŸé—´æ— ç§¯å‹æ—¶æ®µ")
        
        return daily_backlog_summary
    
    def calculate_delay_with_weather(self, data, weather_periods):
        """è®¡ç®—è€ƒè™‘å¤©æ°”åœé£å½±å“çš„å»¶è¯¯æ—¶é—´"""
        delays = []
        
        for idx, flight in data.iterrows():
            planned_departure = flight['è®¡åˆ’ç¦»æ¸¯æ—¶é—´']
            actual_takeoff = flight['å®é™…èµ·é£æ—¶é—´']
            
            if pd.isna(actual_takeoff) or pd.isna(planned_departure):
                delays.append(np.nan)
                continue
            
            # æ£€æŸ¥æ˜¯å¦å—å¤©æ°”åœé£å½±å“
            affected_by_weather = False
            reference_time = planned_departure  # é»˜è®¤å‚è€ƒæ—¶é—´
            
            for period in weather_periods:
                if (flight['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].date() == period['date'] and
                    planned_departure >= period['suspend_start'] and 
                    planned_departure <= period['suspend_end']):
                    
                    # å—å¤©æ°”å½±å“çš„èˆªç­ï¼Œä½¿ç”¨åœé£ç»“æŸæ—¶é—´ä½œä¸ºå‚è€ƒ
                    reference_time = period['suspend_end']
                    affected_by_weather = True
                    break
            
            # è®¡ç®—å»¶è¯¯ï¼šå®é™…èµ·é£æ—¶é—´ - å‚è€ƒæ—¶é—´
            delay_minutes = (actual_takeoff - reference_time).total_seconds() / 60
            delays.append(delay_minutes)
        
        return delays
    
    def load_data(self):
        """è½½å…¥ZGGGèˆªç­æ•°æ®"""
        print(f"\n=== è½½å…¥èˆªç­æ•°æ® ===")
        
        # è¯»å–æ•°æ®
        df = pd.read_excel('/Users/megrez/Library/Mobile Documents/com~apple~CloudDocs/BUAA/ç§‘ç ”/æŒ‘æˆ˜æ¯/èˆªç©ºæŒ‘æˆ˜æ¯/æ•°æ®/5æœˆèˆªç­è¿è¡Œæ•°æ®ï¼ˆè„±æ•ï¼‰.xlsx')
        print(f"åŸå§‹æ•°æ®æ€»è®°å½•æ•°: {len(df)}")
        
        # ç­›é€‰ZGGGèµ·é£èˆªç­
        zggg_flights = df[df['è®¡åˆ’èµ·é£ç«™å››å­—ç '] == 'ZGGG'].copy()
        print(f"ZGGGèµ·é£èˆªç­: {len(zggg_flights)} ç­")
        
        # æ•°æ®æ¸…ç†
        required_cols = ['èˆªç­å·', 'è®¡åˆ’ç¦»æ¸¯æ—¶é—´', 'å®é™…ç¦»æ¸¯æ—¶é—´', 'å®é™…èµ·é£æ—¶é—´']
        valid_data = zggg_flights.dropna(subset=['èˆªç­å·', 'è®¡åˆ’ç¦»æ¸¯æ—¶é—´']).copy()
        print(f"æœ‰åŸºæœ¬æ•°æ®çš„èˆªç­: {len(valid_data)} ç­")
        
        # æ—¶é—´æ ¼å¼è½¬æ¢
        time_cols = ['è®¡åˆ’ç¦»æ¸¯æ—¶é—´', 'å®é™…ç¦»æ¸¯æ—¶é—´', 'å®é™…èµ·é£æ—¶é—´']
        for col in time_cols:
            if col in valid_data.columns:
                valid_data[col] = pd.to_datetime(valid_data[col], errors='coerce')
        
        # å¤„ç†ç¼ºå¤±çš„èµ·é£æ—¶é—´ï¼šç”¨ç¦»æ¸¯æ—¶é—´+20åˆ†é’Ÿä¼°ç®—
        missing_takeoff = valid_data['å®é™…èµ·é£æ—¶é—´'].isna()
        if missing_takeoff.sum() > 0:
            print(f"ç¼ºå¤±å®é™…èµ·é£æ—¶é—´çš„èˆªç­: {missing_takeoff.sum()} ç­")
            # å¯¹äºæœ‰ç¦»æ¸¯æ—¶é—´ä½†æ²¡æœ‰èµ·é£æ—¶é—´çš„ï¼Œç”¨ç¦»æ¸¯æ—¶é—´+20åˆ†é’Ÿä¼°ç®—
            valid_data.loc[missing_takeoff & valid_data['å®é™…ç¦»æ¸¯æ—¶é—´'].notna(), 'å®é™…èµ·é£æ—¶é—´'] = (
                valid_data.loc[missing_takeoff & valid_data['å®é™…ç¦»æ¸¯æ—¶é—´'].notna(), 'å®é™…ç¦»æ¸¯æ—¶é—´'] + 
                pd.Timedelta(minutes=20)
            )
            print(f"å·²ä¸º {(missing_takeoff & valid_data['å®é™…ç¦»æ¸¯æ—¶é—´'].notna()).sum()} ç­èˆªç­ä¼°ç®—èµ·é£æ—¶é—´")
        
        # è¯†åˆ«å¤©æ°”åœé£æ—¶æ®µ
        weather_periods = self.identify_weather_suspension_periods(valid_data)
        
        # è®¡ç®—èµ·é£å»¶è¯¯ï¼ˆè€ƒè™‘å¤©æ°”åœé£å½±å“ï¼‰
        valid_data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] = self.calculate_delay_with_weather(valid_data, weather_periods)
        
        print("ä½¿ç”¨èµ·é£æ—¶é—´è®¡ç®—å»¶è¯¯ï¼Œå·²è€ƒè™‘å¤©æ°”åœé£å½±å“")
        
        # è¿‡æ»¤å¼‚å¸¸æ•°æ®
        valid_data = valid_data[
            (valid_data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] >= -60) &  # å»¶è¯¯ä¸è¶…è¿‡60åˆ†é’Ÿæå‰
            (valid_data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] <= 600)     # å»¶è¯¯ä¸è¶…è¿‡10å°æ—¶
        ]
        
        self.data = valid_data
        print(f"æœ€ç»ˆæœ‰æ•ˆæ•°æ®: {len(self.data)} ç­")
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"\n=== åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ ===")
        print(f"å¹³å‡å»¶è¯¯: {self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'].mean():.1f} åˆ†é’Ÿ")
        print(f"å»¶è¯¯æ ‡å‡†å·®: {self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'].std():.1f} åˆ†é’Ÿ")
        print(f"å»¶è¯¯ä¸­ä½æ•°: {self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'].median():.1f} åˆ†é’Ÿ")
        
        return self.data
    
    def analyze_delay_distribution(self):
        """åˆ†æå»¶è¯¯åˆ†å¸ƒç‰¹å¾"""
        print(f"\n=== å»¶è¯¯åˆ†å¸ƒåˆ†æ ===")
        
        # å»¶è¯¯åˆ†å¸ƒç»Ÿè®¡
        delay_stats = {
            'æå‰ï¼ˆ<0åˆ†é’Ÿï¼‰': (self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] < 0).sum(),
            'å‡†ç‚¹ï¼ˆ0-15åˆ†é’Ÿï¼‰': ((self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] >= 0) & 
                            (self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] <= 15)).sum(),
            'è½»å¾®å»¶è¯¯ï¼ˆ15-30åˆ†é’Ÿï¼‰': ((self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] > 15) & 
                                (self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] <= 30)).sum(),
            'ä¸­ç­‰å»¶è¯¯ï¼ˆ30-60åˆ†é’Ÿï¼‰': ((self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] > 30) & 
                                (self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] <= 60)).sum(),
            'ä¸¥é‡å»¶è¯¯ï¼ˆ60-120åˆ†é’Ÿï¼‰': ((self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] > 60) & 
                                 (self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] <= 120)).sum(),
            'æç«¯å»¶è¯¯ï¼ˆ>120åˆ†é’Ÿï¼‰': (self.data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] > 120).sum()
        }
        
        total_flights = len(self.data)
        print("å»¶è¯¯åˆ†å¸ƒ:")
        for category, count in delay_stats.items():
            percentage = count / total_flights * 100
            print(f"  {category}: {count} ç­ ({percentage:.1f}%)")
        
        return delay_stats
    
    def test_different_thresholds(self):
        """æµ‹è¯•ä¸åŒå»¶è¯¯åˆ¤å®šé˜ˆå€¼å¯¹ç§¯å‹æ—¶æ®µçš„å½±å“"""
        print(f"\n=== æµ‹è¯•ä¸åŒå»¶è¯¯åˆ¤å®šé˜ˆå€¼ ===")
        
        # æµ‹è¯•å¤šä¸ªå»¶è¯¯é˜ˆå€¼
        thresholds = [5, 10, 15, 20, 25, 30, 40, 50, 60, 90, 120]
        results = []
        
        # æ·»åŠ æ—¶é—´ç‰¹å¾
        data = self.data.copy()
        if 'è®¡åˆ’ç¦»æ¸¯æ—¶é—´' in data.columns:
            data['å°æ—¶'] = data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour
            data['æ—¥æœŸ'] = data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date
        
        for threshold in thresholds:
            # æ ‡è®°å»¶è¯¯èˆªç­
            data['å»¶è¯¯æ ‡è®°'] = data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] > threshold
            
            # æŒ‰å°æ—¶ç»Ÿè®¡æ¯å¤©çš„å»¶è¯¯èˆªç­æ•°
            hourly_stats = data.groupby(['æ—¥æœŸ', 'å°æ—¶']).agg({
                'å»¶è¯¯æ ‡è®°': ['count', 'sum']
            })
            hourly_stats.columns = ['èˆªç­æ•°', 'å»¶è¯¯èˆªç­æ•°']
            hourly_stats = hourly_stats.reset_index()
            
            # è¯†åˆ«ç§¯å‹æ—¶æ®µ
            backlog_periods = hourly_stats[
                hourly_stats['å»¶è¯¯èˆªç­æ•°'] >= self.backlog_threshold
            ]
            
            # ç»Ÿè®¡ç§¯å‹æ—¶æ®µå°æ—¶æ•°
            if len(backlog_periods) > 0:
                backlog_hours = sorted(backlog_periods['å°æ—¶'].unique())
                backlog_hours_count = len(backlog_hours)
                backlog_periods_count = len(backlog_periods)
                
                # è®¡ç®—å¹³å‡æ¯å¤©ç§¯å‹å°æ—¶æ•°
                total_days = len(data['æ—¥æœŸ'].unique())
                avg_backlog_hours_per_day = backlog_periods_count / total_days
            else:
                backlog_hours = []
                backlog_hours_count = 0
                backlog_periods_count = 0
                avg_backlog_hours_per_day = 0
            
            # è®¡ç®—å»¶è¯¯èˆªç­æ¯”ä¾‹
            delayed_flights = (data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] > threshold).sum()
            delayed_ratio = delayed_flights / len(data) * 100
            
            results.append({
                'threshold': threshold,
                'delayed_flights': delayed_flights,
                'delayed_ratio': delayed_ratio,
                'backlog_periods': backlog_periods_count,
                'backlog_hours': backlog_hours,
                'backlog_hours_count': backlog_hours_count,
                'avg_backlog_hours_per_day': avg_backlog_hours_per_day
            })
            
            print(f"å»¶è¯¯é˜ˆå€¼ {threshold:3d}åˆ†é’Ÿ: "
                  f"å»¶è¯¯èˆªç­ {delayed_flights:4d}ç­({delayed_ratio:5.1f}%) "
                  f"ç§¯å‹æ—¶æ®µ {backlog_periods_count:3d}ä¸ª "
                  f"æ¶‰åŠå°æ—¶ {backlog_hours_count:2d}ä¸ª "
                  f"æ—¥å‡ç§¯å‹ {avg_backlog_hours_per_day:.1f}å°æ—¶")
        
        return results
    
    def analyze_hourly_patterns(self, threshold=15):
        """åˆ†æä¸åŒæ—¶æ®µçš„å»¶è¯¯æ¨¡å¼"""
        print(f"\n=== å°æ—¶çº§å»¶è¯¯æ¨¡å¼åˆ†æï¼ˆå»¶è¯¯é˜ˆå€¼: {threshold}åˆ†é’Ÿï¼‰===")
        
        data = self.data.copy()
        data['å°æ—¶'] = data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour
        data['æ—¥æœŸ'] = data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date
        
        data['å»¶è¯¯æ ‡è®°'] = data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] > threshold
        
        # æŒ‰å°æ—¶åˆ†ç»„ç»Ÿè®¡
        hourly_summary = data.groupby('å°æ—¶').agg({
            'èµ·é£å»¶è¯¯åˆ†é’Ÿ': ['count', 'mean', 'std', 'median'],
            'å»¶è¯¯æ ‡è®°': ['sum', 'mean']
        }).round(2)
        
        hourly_summary.columns = ['èˆªç­æ•°', 'å¹³å‡å»¶è¯¯', 'å»¶è¯¯æ ‡å‡†å·®', 'å»¶è¯¯ä¸­ä½æ•°', 'å»¶è¯¯èˆªç­æ•°', 'å»¶è¯¯ç‡']
        
        # è¯†åˆ«æ½œåœ¨çš„ç§¯å‹æ—¶æ®µ
        potential_backlog_hours = hourly_summary[
            hourly_summary['å»¶è¯¯èˆªç­æ•°'] >= self.backlog_threshold / len(data['æ—¥æœŸ'].unique())
        ].index.tolist()
        
        print("å„å°æ—¶å»¶è¯¯æƒ…å†µ:")
        print("æ—¶æ®µ    èˆªç­æ•°  å¹³å‡å»¶è¯¯  å»¶è¯¯ç‡    å»¶è¯¯èˆªç­æ•°  æ˜¯å¦ç§¯å‹")
        print("-" * 55)
        
        for hour in range(24):
            if hour in hourly_summary.index:
                stats = hourly_summary.loc[hour]
                is_backlog = "æ˜¯" if hour in potential_backlog_hours else "å¦"
                print(f"{hour:02d}:00  {stats['èˆªç­æ•°']:6.0f}  {stats['å¹³å‡å»¶è¯¯']:7.1f}  "
                      f"{stats['å»¶è¯¯ç‡']*100:6.1f}%  {stats['å»¶è¯¯èˆªç­æ•°']:8.0f}   {is_backlog}")
            else:
                print(f"{hour:02d}:00      0      0.0     0.0%         0   å¦")
        
        return hourly_summary
    
    def find_optimal_threshold(self):
        """å¯»æ‰¾æœ€ä½³çš„å»¶è¯¯åˆ¤å®šé˜ˆå€¼"""
        print(f"\n=== å¯»æ‰¾æœ€ä½³å»¶è¯¯åˆ¤å®šé˜ˆå€¼ï¼ˆç§¯å‹é—¨æ§›å›ºå®šä¸º{self.backlog_threshold}ç­ï¼‰===")
        
        # ç›®æ ‡ï¼šç§¯å‹æ—¶æ®µåº”è¯¥ç¬¦åˆèˆªç©ºè¿è¥è§„å¾‹
        # ç†æƒ³æƒ…å†µï¼šæ—©é«˜å³°(7-9)ã€æ™šé«˜å³°(18-21)ã€å¯èƒ½çš„åˆé—´å¿™ç¢Œ(12-14)
        expected_busy_hours = [7, 8, 9, 12, 13, 14, 18, 19, 20, 21]
        
        results = self.test_different_thresholds()
        
        print(f"\nè¯„ä¼°æ ‡å‡†:")
        print("1. ç§¯å‹æ—¶æ®µåº”è¯¥é›†ä¸­åœ¨ç¹å¿™æ—¶æ®µï¼Œé¿å…å…¨å¤©ç§¯å‹")
        print("2. å»¶è¯¯èˆªç­æ¯”ä¾‹åº”è¯¥åˆç†ï¼ˆ15-40%ï¼‰- è€ƒè™‘å¤©æ°”å½±å“è°ƒæ•´èŒƒå›´")
        print("3. ç§¯å‹æ—¶æ®µåº”è¯¥æœ‰æ˜æ˜¾çš„æ—¶é—´é›†ä¸­æ€§")
        print("4. å¤©æ°”åœé£æ¢å¤åçš„å»¶è¯¯è®¡ç®—æ›´åˆç†")
        
        best_threshold = None
        best_score = -1
        
        for result in results:
            threshold = result['threshold']
            backlog_hours = result['backlog_hours']
            delayed_ratio = result['delayed_ratio']
            backlog_hours_count = result['backlog_hours_count']
            
            # è®¡ç®—è¯„åˆ†
            score = 0
            
            # 1. å»¶è¯¯æ¯”ä¾‹åˆç†æ€§ï¼ˆ15-40%æ¯”è¾ƒåˆç†ï¼Œè€ƒè™‘å¤©æ°”å½±å“ï¼‰
            if 15 <= delayed_ratio <= 40:
                score += 30
            elif 10 <= delayed_ratio < 15 or 40 < delayed_ratio <= 50:
                score += 20
            elif delayed_ratio < 10 or delayed_ratio > 50:
                score += 0
            
            # 2. ç§¯å‹æ—¶æ®µæ•°é‡åˆç†æ€§ï¼ˆé¿å…å…¨å¤©ç§¯å‹ï¼‰
            if 3 <= backlog_hours_count <= 8:
                score += 30
            elif 2 <= backlog_hours_count < 3 or 8 < backlog_hours_count <= 12:
                score += 20
            elif backlog_hours_count < 2 or backlog_hours_count > 12:
                score += 10
            
            # 3. ç§¯å‹æ—¶æ®µä¸ç¹å¿™æ—¶æ®µçš„é‡åˆåº¦
            overlap = len(set(backlog_hours) & set(expected_busy_hours))
            if overlap >= 4:
                score += 25
            elif overlap >= 2:
                score += 15
            elif overlap >= 1:
                score += 10
            
            # 4. é¿å…å¤œé—´ç§¯å‹ï¼ˆ0-6ç‚¹ä¸åº”è¯¥æœ‰ç§¯å‹ï¼‰
            night_backlog = len([h for h in backlog_hours if 0 <= h <= 6])
            if night_backlog == 0:
                score += 15
            elif night_backlog <= 2:
                score += 10
            
            print(f"é˜ˆå€¼ {threshold:3d}åˆ†é’Ÿ: è¯„åˆ† {score:3d}/100 "
                  f"(å»¶è¯¯ç‡{delayed_ratio:5.1f}% ç§¯å‹{backlog_hours_count:2d}å°æ—¶ "
                  f"ç¹å¿™é‡åˆ{overlap}ä¸ª å¤œé—´ç§¯å‹{night_backlog}ä¸ª)")
            
            if score > best_score:
                best_score = score
                best_threshold = threshold
        
        print(f"\nğŸ† æ¨èæœ€ä½³å»¶è¯¯åˆ¤å®šé˜ˆå€¼: {best_threshold} åˆ†é’Ÿ (è¯„åˆ†: {best_score}/100)")
        
        # å±•ç¤ºæœ€ä½³é˜ˆå€¼çš„è¯¦ç»†åˆ†æ
        if best_threshold:
            print(f"\n=== ä½¿ç”¨æœ€ä½³é˜ˆå€¼ {best_threshold} åˆ†é’Ÿçš„è¯¦ç»†åˆ†æ ===")
            self.analyze_hourly_patterns(threshold=best_threshold)
            
        return best_threshold, best_score
    
    def visualize_delay_patterns(self, threshold=15):
        """å¯è§†åŒ–å»¶è¯¯æ¨¡å¼ï¼ˆä½¿ç”¨è¿‡æ»¤åçš„æ•°æ®ï¼‰"""
        print(f"\n=== ç”Ÿæˆå»¶è¯¯æ¨¡å¼å¯è§†åŒ–å›¾è¡¨ ===")
        
        # é¦–å…ˆè¿›è¡Œæ•°æ®è¿‡æ»¤ï¼Œæ’é™¤ç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µ
        data = self.data.copy()
        
        # è¯†åˆ«ç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µ
        problematic_hours = self.identify_systematic_problematic_hours(data)
        
        # æ’é™¤ç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µçš„æ•°æ®
        if problematic_hours:
            problematic_hour_list = [h['hour'] for h in problematic_hours]
            original_count = len(data)
            data = data[~data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour.isin(problematic_hour_list)]
            excluded_count = original_count - len(data)
            print(f"å¯è§†åŒ–åˆ†æä¸­æ’é™¤ç³»ç»Ÿæ€§é—®é¢˜æ—¶æ®µæ•°æ®: {excluded_count} ä¸ªèˆªç­")
        
        data['å°æ—¶'] = data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour
        data['æ—¥æœŸ'] = data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date
        
        data['å»¶è¯¯æ ‡è®°'] = data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] > threshold
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'ZGGGæœºåœºå»¶è¯¯æ¨¡å¼åˆ†æï¼ˆå»¶è¯¯é˜ˆå€¼: {threshold}åˆ†é’Ÿï¼‰', fontsize=16)
        
        # 1. æ¯å°æ—¶å¹³å‡å»¶è¯¯æ—¶é—´
        hourly_avg_delay = data.groupby('å°æ—¶')['èµ·é£å»¶è¯¯åˆ†é’Ÿ'].mean()
        axes[0,0].bar(hourly_avg_delay.index, hourly_avg_delay.values, color='skyblue')
        axes[0,0].set_title('å„å°æ—¶å¹³å‡å»¶è¯¯æ—¶é—´')
        axes[0,0].set_xlabel('å°æ—¶')
        axes[0,0].set_ylabel('å¹³å‡å»¶è¯¯(åˆ†é’Ÿ)')
        axes[0,0].grid(True, alpha=0.3)
        
        # 2. æ¯å°æ—¶æ—¥å‡å»¶è¯¯èˆªç­æ•°é‡ï¼ˆä¿®æ­£ï¼‰
        daily_hourly_delayed = data.groupby(['æ—¥æœŸ', 'å°æ—¶'])['å»¶è¯¯æ ‡è®°'].sum().reset_index()
        hourly_avg_delayed = daily_hourly_delayed.groupby('å°æ—¶')['å»¶è¯¯æ ‡è®°'].mean()
        
        axes[0,1].bar(hourly_avg_delayed.index, hourly_avg_delayed.values, color='orange')
        axes[0,1].axhline(y=self.backlog_threshold, color='red', linestyle='--', 
                         label=f'ç§¯å‹é˜ˆå€¼({self.backlog_threshold}ç­/å°æ—¶)')
        axes[0,1].set_title('å„å°æ—¶æ—¥å‡å»¶è¯¯èˆªç­æ•°é‡')
        axes[0,1].set_xlabel('å°æ—¶')
        axes[0,1].set_ylabel('æ—¥å‡å»¶è¯¯èˆªç­æ•°')
        axes[0,1].legend()
        axes[0,1].grid(True, alpha=0.3)
        
        # 3. å»¶è¯¯åˆ†å¸ƒç›´æ–¹å›¾
        axes[1,0].hist(data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'], bins=50, color='lightgreen', alpha=0.7)
        axes[1,0].axvline(x=threshold, color='red', linestyle='--', 
                         label=f'å»¶è¯¯é˜ˆå€¼({threshold}åˆ†é’Ÿ)')
        axes[1,0].set_title('å»¶è¯¯æ—¶é—´åˆ†å¸ƒ')
        axes[1,0].set_xlabel('å»¶è¯¯æ—¶é—´(åˆ†é’Ÿ)')
        axes[1,0].set_ylabel('èˆªç­æ•°')
        axes[1,0].legend()
        axes[1,0].grid(True, alpha=0.3)
        
        # 4. çƒ­åŠ›å›¾ï¼šæ—¥æœŸ-å°æ—¶å»¶è¯¯èˆªç­æ•°
        pivot_data = data.groupby(['æ—¥æœŸ', 'å°æ—¶'])['å»¶è¯¯æ ‡è®°'].sum().reset_index()
        pivot_matrix = pivot_data.pivot(index='æ—¥æœŸ', columns='å°æ—¶', values='å»¶è¯¯æ ‡è®°')
        pivot_matrix = pivot_matrix.fillna(0)
        
        im = axes[1,1].imshow(pivot_matrix.values, cmap='YlOrRd', aspect='auto')
        axes[1,1].set_title('æ¯æ—¥å„å°æ—¶å»¶è¯¯èˆªç­æ•°çƒ­åŠ›å›¾')
        axes[1,1].set_xlabel('å°æ—¶')
        axes[1,1].set_ylabel('æ—¥æœŸ')
        
        # è®¾ç½®åˆ»åº¦
        axes[1,1].set_xticks(range(0, 24, 2))
        axes[1,1].set_xticklabels(range(0, 24, 2))
        
        plt.colorbar(im, ax=axes[1,1], label='å»¶è¯¯èˆªç­æ•°')
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        filename = f'ZGGGæ¯æ—¥ç§¯å‹æ¨¡å¼åˆ†æ_{threshold}åˆ†é’Ÿé˜ˆå€¼.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"å›¾è¡¨å·²ä¿å­˜ä¸º: {filename}")
        plt.show()

def main():
    """ä¸»å‡½æ•°"""
    analyzer = ZGGGBacklogAnalyzer()
    
    # 1. è½½å…¥æ•°æ®
    data = analyzer.load_data()
    if data is None or len(data) == 0:
        print("âŒ æ•°æ®è½½å…¥å¤±è´¥")
        return
    
    # 2. åˆ†æå»¶è¯¯åˆ†å¸ƒ
    analyzer.analyze_delay_distribution()
    
    # 3. æµ‹è¯•ä¸åŒé˜ˆå€¼
    analyzer.test_different_thresholds()
    
    # 4. å¯»æ‰¾æœ€ä½³é˜ˆå€¼
    best_threshold, best_score = analyzer.find_optimal_threshold()
    
    # 5. é«˜çº§ç§¯å‹åˆ†æï¼ˆæ’é™¤ç‰¹æ®Šæƒ…å†µï¼‰
    if best_threshold:
        congestion_analysis = analyzer.identify_congestion_periods_advanced(threshold=best_threshold)
        print(f"\n=== ä½¿ç”¨æœ€ä½³é˜ˆå€¼ {best_threshold} åˆ†é’Ÿè¿›è¡Œç§¯å‹åˆ†æ ===")
        
        # æ¯æ—¥ç§¯å‹æ¨¡å¼åˆ†æ
        daily_backlog = analyzer.analyze_daily_congestion_patterns(threshold=best_threshold)
    
    # 6. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    if best_threshold:
        analyzer.visualize_delay_patterns(threshold=best_threshold)

if __name__ == "__main__":
    main()
