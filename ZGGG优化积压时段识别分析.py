#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ZGGGä¼˜åŒ–ç§¯å‹æ—¶æ®µè¯†åˆ«åˆ†æ
é‡æ–°å®šä¹‰ç§¯å‹æ—¶æ®µçš„è¯†åˆ«é€»è¾‘ï¼Œä½¿å…¶æ›´ç¬¦åˆå®é™…è¿è¥æƒ…å†µ
ç§¯å‹æ—¶æ®µåº”è¯¥æ˜¯çŸ­æ—¶çš„ã€æ³¢åŠ¨æ€§çš„ç°è±¡ï¼Œè€Œéé•¿æ—¶é—´æŒç»­çŠ¶æ€
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥ä»¿çœŸå™¨
from ZGGGèµ·é£ä»¿çœŸç³»ç»Ÿ import ZGGGDepartureSimulator

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

class OptimizedBacklogAnalyzer:
    def __init__(self, delay_threshold=4, base_backlog_threshold=10):
        """
        ä¼˜åŒ–çš„ç§¯å‹åˆ†æå™¨
        
        Args:
            delay_threshold: å»¶è¯¯åˆ¤å®šé˜ˆå€¼(åˆ†é’Ÿ)
            base_backlog_threshold: åŸºç¡€ç§¯å‹åˆ¤å®šé˜ˆå€¼(ç­æ¬¡/å°æ—¶)
        """
        self.delay_threshold = delay_threshold
        self.base_backlog_threshold = base_backlog_threshold
        self.real_data = None
        
        print(f"=== ä¼˜åŒ–ç§¯å‹åˆ†æå™¨åˆå§‹åŒ– ===")
        print(f"å»¶è¯¯åˆ¤å®šé˜ˆå€¼: {delay_threshold} åˆ†é’Ÿ")
        print(f"åŸºç¡€ç§¯å‹é˜ˆå€¼: {base_backlog_threshold} ç­/å°æ—¶")
    
    def load_real_data(self):
        """è½½å…¥çœŸå®æ•°æ®"""
        print(f"\n=== è½½å…¥çœŸå®æ•°æ® ===")
        
        df = pd.read_excel('/Users/megrez/Library/Mobile Documents/com~apple~CloudDocs/BUAA/ç§‘ç ”/æŒ‘æˆ˜æ¯/èˆªç©ºæŒ‘æˆ˜æ¯/æ•°æ®/5æœˆèˆªç­è¿è¡Œæ•°æ®ï¼ˆè„±æ•ï¼‰.xlsx')
        
        # æå–ZGGGèµ·é£èˆªç­
        zggg_dep = df[df['å®é™…èµ·é£ç«™å››å­—ç '] == 'ZGGG'].copy()
        
        # è½¬æ¢æ—¶é—´å­—æ®µ
        time_fields = ['è®¡åˆ’ç¦»æ¸¯æ—¶é—´', 'å®é™…ç¦»æ¸¯æ—¶é—´', 'å®é™…èµ·é£æ—¶é—´']
        for field in time_fields:
            zggg_dep[field] = pd.to_datetime(zggg_dep[field], errors='coerce')
        
        # åªä¿ç•™æœ‰å®Œæ•´æ—¶é—´æ•°æ®çš„èˆªç­
        self.real_data = zggg_dep.dropna(subset=time_fields).copy()
        
        # è®¡ç®—å»¶è¯¯æ—¶é—´
        self.real_data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] = (
            self.real_data['å®é™…èµ·é£æ—¶é—´'] - self.real_data['è®¡åˆ’ç¦»æ¸¯æ—¶é—´']
        ).dt.total_seconds() / 60
        
        print(f"çœŸå®æ•°æ®è½½å…¥: {len(self.real_data)} ç­èˆªç­")
        return self.real_data
    
    def analyze_hourly_patterns(self):
        """åˆ†ææ¯å°æ—¶çš„å»¶è¯¯æ¨¡å¼"""
        print(f"\n=== åˆ†ææ¯å°æ—¶å»¶è¯¯æ¨¡å¼ ===")
        
        # è¯†åˆ«å»¶è¯¯èˆªç­
        delayed_flights = self.real_data[
            self.real_data['èµ·é£å»¶è¯¯åˆ†é’Ÿ'] > self.delay_threshold
        ].copy()
        
        print(f"å»¶è¯¯èˆªç­æ€»æ•°: {len(delayed_flights)} ç­ ({len(delayed_flights)/len(self.real_data)*100:.1f}%)")
        
        # æŒ‰å°æ—¶ç»Ÿè®¡
        delayed_flights['hour'] = delayed_flights['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour
        delayed_flights['date'] = delayed_flights['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date
        
        # è®¡ç®—æ¯å°æ—¶çš„ç»Ÿè®¡ä¿¡æ¯
        hourly_stats = {}
        
        for hour in range(24):
            hour_data = delayed_flights[delayed_flights['hour'] == hour]
            if len(hour_data) > 0:
                daily_counts = hour_data.groupby('date').size()
                hourly_stats[hour] = {
                    'daily_mean': daily_counts.mean(),
                    'daily_std': daily_counts.std(),
                    'daily_max': daily_counts.max(),
                    'daily_min': daily_counts.min(),
                    'total_days': len(daily_counts),
                    'zero_days': 31 - len(daily_counts)  # 5æœˆ31å¤©å‡å»æœ‰å»¶è¯¯çš„å¤©æ•°
                }
            else:
                hourly_stats[hour] = {
                    'daily_mean': 0,
                    'daily_std': 0,
                    'daily_max': 0,
                    'daily_min': 0,
                    'total_days': 0,
                    'zero_days': 31
                }
        
        return hourly_stats, delayed_flights
    
    def identify_dynamic_backlog_periods(self, hourly_stats):
        """åŠ¨æ€è¯†åˆ«ç§¯å‹æ—¶æ®µ"""
        print(f"\n=== åŠ¨æ€è¯†åˆ«ç§¯å‹æ—¶æ®µ ===")
        
        # è®¡ç®—åŠ¨æ€é˜ˆå€¼
        all_means = [stats['daily_mean'] for stats in hourly_stats.values()]
        overall_mean = np.mean(all_means)
        overall_std = np.std(all_means)
        
        print(f"å…¨å¤©å»¶è¯¯èˆªç­å‡å€¼: {overall_mean:.1f} ç­/å°æ—¶")
        print(f"å…¨å¤©å»¶è¯¯èˆªç­æ ‡å‡†å·®: {overall_std:.1f}")
        
        # æ–¹æ³•1: åŸºäºç»Ÿè®¡å¼‚å¸¸çš„ç§¯å‹è¯†åˆ«
        # ç§¯å‹å®šä¹‰ï¼šæ˜¾è‘—é«˜äºå¹³å‡æ°´å¹³ä¸”å˜å¼‚æ€§è¾ƒå¤§çš„æ—¶æ®µ
        backlog_criteria = {
            'statistical': [],  # ç»Ÿè®¡å¼‚å¸¸ç§¯å‹
            'absolute': [],     # ç»å¯¹é˜ˆå€¼ç§¯å‹
            'relative': []      # ç›¸å¯¹æ³¢åŠ¨ç§¯å‹
        }
        
        print(f"\nå„å°æ—¶å»¶è¯¯æƒ…å†µåˆ†æ:")
        for hour in range(24):
            stats = hourly_stats[hour]
            mean_val = stats['daily_mean']
            std_val = stats['daily_std']
            max_val = stats['daily_max']
            
            print(f"  {hour:02d}:00-{hour+1:02d}:00: å‡å€¼{mean_val:.1f}, æ ‡å‡†å·®{std_val:.1f}, æœ€å¤§{max_val}")
            
            # ç»Ÿè®¡å¼‚å¸¸æ ‡å‡†ï¼šå‡å€¼è¶…è¿‡å…¨ä½“å‡å€¼+1å€æ ‡å‡†å·®
            if mean_val > (overall_mean + overall_std):
                backlog_criteria['statistical'].append(hour)
            
            # ç»å¯¹é˜ˆå€¼æ ‡å‡†ï¼šå‡å€¼è¶…è¿‡åŸºç¡€é˜ˆå€¼
            if mean_val > self.base_backlog_threshold:
                backlog_criteria['absolute'].append(hour)
            
            # ç›¸å¯¹æ³¢åŠ¨æ ‡å‡†ï¼šæ ‡å‡†å·®è¾ƒå¤§ä¸”å‡å€¼è¾ƒé«˜çš„æ—¶æ®µ
            if std_val > 5 and mean_val > overall_mean:
                backlog_criteria['relative'].append(hour)
        
        return backlog_criteria, overall_mean, overall_std
    
    def identify_surge_periods(self, hourly_stats):
        """è¯†åˆ«æµé‡æ¿€å¢æ—¶æ®µ"""
        print(f"\n=== è¯†åˆ«æµé‡æ¿€å¢æ—¶æ®µ ===")
        
        surge_periods = []
        
        # è½½å…¥æ‰€æœ‰èˆªç­æ•°æ®ï¼ˆä¸ä»…ä»…æ˜¯å»¶è¯¯èˆªç­ï¼‰
        all_flights = self.real_data.copy()
        all_flights['hour'] = all_flights['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.hour
        all_flights['date'] = all_flights['è®¡åˆ’ç¦»æ¸¯æ—¶é—´'].dt.date
        
        # è®¡ç®—æ¯å°æ—¶æ€»èˆªç­é‡
        hourly_total_stats = {}
        for hour in range(24):
            hour_data = all_flights[all_flights['hour'] == hour]
            daily_counts = hour_data.groupby('date').size()
            hourly_total_stats[hour] = {
                'daily_mean': daily_counts.mean() if len(daily_counts) > 0 else 0,
                'daily_std': daily_counts.std() if len(daily_counts) > 0 else 0
            }
        
        # è¯†åˆ«æµé‡æ¿€å¢å¯¼è‡´çš„ç§¯å‹
        print(f"å„å°æ—¶æ€»èˆªç­æµé‡åˆ†æ:")
        for hour in range(24):
            total_stats = hourly_total_stats[hour]
            delay_stats = hourly_stats[hour]
            
            total_mean = total_stats['daily_mean']
            delay_mean = delay_stats['daily_mean']
            delay_rate = (delay_mean / total_mean * 100) if total_mean > 0 else 0
            
            print(f"  {hour:02d}:00-{hour+1:02d}:00: æ€»é‡{total_mean:.1f}, å»¶è¯¯{delay_mean:.1f}, å»¶è¯¯ç‡{delay_rate:.1f}%")
            
            # ç§¯å‹åˆ¤å®šï¼šæ€»é‡é«˜ä¸”å»¶è¯¯ç‡é«˜çš„æ—¶æ®µ
            if total_mean > 15 and delay_rate > 70:  # èˆªç­é‡>15ä¸”å»¶è¯¯ç‡>70%
                surge_periods.append({
                    'hour': hour,
                    'total_flights': total_mean,
                    'delayed_flights': delay_mean,
                    'delay_rate': delay_rate
                })
        
        return surge_periods, hourly_total_stats
    
    def find_continuous_backlog_periods(self, backlog_hours):
        """æŸ¥æ‰¾è¿ç»­ç§¯å‹æ—¶æ®µï¼Œé™åˆ¶åœ¨åˆç†èŒƒå›´å†…"""
        if not backlog_hours:
            return []
        
        hours = sorted(backlog_hours)
        continuous_periods = []
        current_period = [hours[0]]
        
        for i in range(1, len(hours)):
            if hours[i] - hours[i-1] == 1:  # è¿ç»­å°æ—¶
                current_period.append(hours[i])
            else:
                # æ£€æŸ¥è¿ç»­æ—¶æ®µé•¿åº¦
                if 1 <= len(current_period) <= 5:  # åˆç†çš„ç§¯å‹æŒç»­æ—¶é—´ï¼š1-5å°æ—¶
                    continuous_periods.append(current_period)
                elif len(current_period) > 5:
                    # é•¿æ—¶æ®µå¯èƒ½æ˜¯æŒç»­ç¹å¿™è€ŒéçœŸæ­£ç§¯å‹ï¼Œåˆ†å‰²å¤„ç†
                    print(f"  é•¿æ—¶æ®µ{current_period[0]:02d}:00-{current_period[-1]+1:02d}:00 (æŒç»­{len(current_period)}å°æ—¶) - å¯èƒ½éçœŸå®ç§¯å‹")
                
                current_period = [hours[i]]
        
        # å¤„ç†æœ€åä¸€ä¸ªæ—¶æ®µ
        if 1 <= len(current_period) <= 5:
            continuous_periods.append(current_period)
        elif len(current_period) > 5:
            print(f"  é•¿æ—¶æ®µ{current_period[0]:02d}:00-{current_period[-1]+1:02d}:00 (æŒç»­{len(current_period)}å°æ—¶) - å¯èƒ½éçœŸå®ç§¯å‹")
        
        return continuous_periods
    
    def analyze_optimized_backlog(self):
        """ç»¼åˆåˆ†æä¼˜åŒ–åçš„ç§¯å‹æ—¶æ®µ"""
        print(f"\n" + "="*60)
        print(f"                ä¼˜åŒ–ç§¯å‹æ—¶æ®µåˆ†æ")
        print(f"="*60)
        
        # 1. åˆ†ææ¯å°æ—¶æ¨¡å¼
        hourly_stats, delayed_flights = self.analyze_hourly_patterns()
        
        # 2. åŠ¨æ€è¯†åˆ«ç§¯å‹æ—¶æ®µ
        backlog_criteria, overall_mean, overall_std = self.identify_dynamic_backlog_periods(hourly_stats)
        
        # 3. è¯†åˆ«æµé‡æ¿€å¢æ—¶æ®µ
        surge_periods, hourly_total_stats = self.identify_surge_periods(hourly_stats)
        
        # 4. ç»¼åˆåˆ¤å®šæœ€ç»ˆç§¯å‹æ—¶æ®µ
        print(f"\n=== ç»¼åˆåˆ¤å®šç§¯å‹æ—¶æ®µ ===")
        print(f"ç»Ÿè®¡å¼‚å¸¸ç§¯å‹æ—¶æ®µ: {len(backlog_criteria['statistical'])} ä¸ª: {backlog_criteria['statistical']}")
        print(f"ç»å¯¹é˜ˆå€¼ç§¯å‹æ—¶æ®µ: {len(backlog_criteria['absolute'])} ä¸ª: {backlog_criteria['absolute']}")
        print(f"ç›¸å¯¹æ³¢åŠ¨ç§¯å‹æ—¶æ®µ: {len(backlog_criteria['relative'])} ä¸ª: {backlog_criteria['relative']}")
        print(f"æµé‡æ¿€å¢ç§¯å‹æ—¶æ®µ: {len(surge_periods)} ä¸ª: {[p['hour'] for p in surge_periods]}")
        
        # ç»¼åˆå¤šç§æ ‡å‡†ï¼Œå–äº¤é›†ä½œä¸ºçœŸæ­£çš„ç§¯å‹æ—¶æ®µ
        final_backlog_hours = set(backlog_criteria['statistical']) & set([p['hour'] for p in surge_periods])
        
        if not final_backlog_hours:
            # å¦‚æœäº¤é›†ä¸ºç©ºï¼Œä½¿ç”¨ç»Ÿè®¡å¼‚å¸¸æ ‡å‡†ä½†é™åˆ¶è¿ç»­é•¿åº¦
            final_backlog_hours = set(backlog_criteria['statistical'])
        
        print(f"\næœ€ç»ˆç§¯å‹æ—¶æ®µ: {len(final_backlog_hours)} ä¸ª: {sorted(final_backlog_hours)}")
        
        # 5. æŸ¥æ‰¾è¿ç»­ç§¯å‹æ—¶æ®µï¼ˆé™åˆ¶åˆç†é•¿åº¦ï¼‰
        continuous_periods = self.find_continuous_backlog_periods(list(final_backlog_hours))
        
        print(f"\nè¿ç»­ç§¯å‹æ—¶æ®µåˆ†æ:")
        for i, period in enumerate(continuous_periods, 1):
            start, end = period[0], period[-1]
            duration = len(period)
            total_delays = sum([hourly_stats[h]['daily_mean'] for h in period])
            print(f"  è¿ç»­ç§¯å‹{i}: {start:02d}:00-{end+1:02d}:00 (æŒç»­{duration}å°æ—¶, æ—¥å‡{total_delays:.1f}ç­å»¶è¯¯)")
        
        return {
            'hourly_stats': hourly_stats,
            'backlog_criteria': backlog_criteria,
            'surge_periods': surge_periods,
            'final_backlog_hours': sorted(final_backlog_hours),
            'continuous_periods': continuous_periods,
            'delayed_flights': delayed_flights,
            'overall_mean': overall_mean,
            'overall_std': overall_std
        }
    
    def visualize_optimized_analysis(self, analysis_result):
        """å¯è§†åŒ–ä¼˜åŒ–åçš„åˆ†æç»“æœ"""
        fig, axes = plt.subplots(3, 2, figsize=(16, 18))
        
        hourly_stats = analysis_result['hourly_stats']
        
        # 1. æ¯å°æ—¶å»¶è¯¯ç»Ÿè®¡å¯¹æ¯”
        ax1 = axes[0, 0]
        hours = range(24)
        means = [hourly_stats[h]['daily_mean'] for h in hours]
        stds = [hourly_stats[h]['daily_std'] for h in hours]
        maxs = [hourly_stats[h]['daily_max'] for h in hours]
        
        ax1.bar(hours, means, alpha=0.6, label='æ—¥å‡å»¶è¯¯', color='blue')
        ax1.errorbar(hours, means, yerr=stds, fmt='none', color='red', alpha=0.7, label='æ ‡å‡†å·®')
        ax1.plot(hours, maxs, 'ro-', alpha=0.7, label='æœ€å¤§å€¼')
        
        # æ ‡è®°ä¸åŒç±»å‹çš„ç§¯å‹æ—¶æ®µ
        for h in analysis_result['backlog_criteria']['statistical']:
            ax1.axvspan(h-0.4, h+0.4, alpha=0.3, color='red', label='ç»Ÿè®¡å¼‚å¸¸' if h == analysis_result['backlog_criteria']['statistical'][0] else '')
        
        for period in analysis_result['surge_periods']:
            h = period['hour']
            ax1.axvspan(h-0.4, h+0.4, alpha=0.3, color='orange', label='æµé‡æ¿€å¢' if h == analysis_result['surge_periods'][0]['hour'] else '')
        
        ax1.axhline(y=analysis_result['overall_mean'], color='green', linestyle='--', alpha=0.7, label='å…¨å¤©å‡å€¼')
        ax1.axhline(y=self.base_backlog_threshold, color='purple', linestyle='--', alpha=0.7, label='åŸºç¡€é˜ˆå€¼')
        
        ax1.set_xlabel('å°æ—¶')
        ax1.set_ylabel('å»¶è¯¯èˆªç­æ•°')
        ax1.set_title('æ¯å°æ—¶å»¶è¯¯ç»Ÿè®¡åˆ†æ')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. å»¶è¯¯ç‡vsæ€»èˆªç­é‡æ•£ç‚¹å›¾
        ax2 = axes[0, 1]
        surge_data = analysis_result['surge_periods']
        if surge_data:
            total_flights = [p['total_flights'] for p in surge_data]
            delay_rates = [p['delay_rate'] for p in surge_data]
            hours_surge = [p['hour'] for p in surge_data]
            
            scatter = ax2.scatter(total_flights, delay_rates, c=hours_surge, cmap='viridis', s=100, alpha=0.7)
            plt.colorbar(scatter, ax=ax2, label='å°æ—¶')
            
            for i, (x, y, h) in enumerate(zip(total_flights, delay_rates, hours_surge)):
                ax2.annotate(f'{h:02d}h', (x, y), xytext=(5, 5), textcoords='offset points', fontsize=10)
        
        ax2.set_xlabel('æ€»èˆªç­é‡(æ¶/å°æ—¶)')
        ax2.set_ylabel('å»¶è¯¯ç‡(%)')
        ax2.set_title('æµé‡vså»¶è¯¯ç‡åˆ†æ')
        ax2.grid(True, alpha=0.3)
        
        # 3. ç§¯å‹æ—¶æ®µå¯¹æ¯”ï¼ˆä¸åŒæ ‡å‡†ï¼‰
        ax3 = axes[1, 0]
        criteria_names = ['ç»Ÿè®¡å¼‚å¸¸', 'ç»å¯¹é˜ˆå€¼', 'ç›¸å¯¹æ³¢åŠ¨', 'æµé‡æ¿€å¢', 'æœ€ç»ˆç»“æœ']
        criteria_counts = [
            len(analysis_result['backlog_criteria']['statistical']),
            len(analysis_result['backlog_criteria']['absolute']),
            len(analysis_result['backlog_criteria']['relative']),
            len(analysis_result['surge_periods']),
            len(analysis_result['final_backlog_hours'])
        ]
        
        bars = ax3.bar(criteria_names, criteria_counts, alpha=0.7, color=['red', 'orange', 'yellow', 'green', 'blue'])
        ax3.set_ylabel('ç§¯å‹æ—¶æ®µæ•°é‡')
        ax3.set_title('ä¸åŒæ ‡å‡†ä¸‹çš„ç§¯å‹æ—¶æ®µè¯†åˆ«')
        plt.setp(ax3.get_xticklabels(), rotation=45, ha='right')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, count in zip(bars, criteria_counts):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{count}', ha='center', va='bottom', fontweight='bold')
        
        # 4. è¿ç»­ç§¯å‹æ—¶æ®µå¯è§†åŒ–
        ax4 = axes[1, 1]
        continuous_periods = analysis_result['continuous_periods']
        if continuous_periods:
            colors = plt.cm.Set3(np.linspace(0, 1, len(continuous_periods)))
            for i, (period, color) in enumerate(zip(continuous_periods, colors)):
                start, end = period[0], period[-1]
                duration = len(period)
                ax4.barh(i, duration, left=start, alpha=0.7, color=color)
                ax4.text(start + duration/2, i, f'{duration}h', ha='center', va='center', fontweight='bold')
            
            ax4.set_xlabel('å°æ—¶')
            ax4.set_ylabel('è¿ç»­ç§¯å‹æ—¶æ®µåºå·')
            ax4.set_title('è¿ç»­ç§¯å‹æ—¶æ®µåˆ†æ')
            ax4.set_xlim(0, 24)
            ax4.set_xticks(range(0, 25, 4))
            ax4.set_xticklabels([f'{i}:00' for i in range(0, 25, 4)])
        else:
            ax4.text(0.5, 0.5, 'æ— è¿ç»­ç§¯å‹æ—¶æ®µ', ha='center', va='center', transform=ax4.transAxes, fontsize=14)
            ax4.set_title('è¿ç»­ç§¯å‹æ—¶æ®µåˆ†æ')
        
        # 5. ä¼˜åŒ–å‰åå¯¹æ¯”
        ax5 = axes[2, 0]
        old_method_hours = list(range(7, 23))  # åŸæ¥çš„æ–¹æ³•ï¼š7-22ç‚¹å…¨éƒ¨è®¤ä¸ºæ˜¯ç§¯å‹
        new_method_hours = analysis_result['final_backlog_hours']
        
        comparison_data = {
            'åŸæ–¹æ³•': len(old_method_hours),
            'ä¼˜åŒ–æ–¹æ³•': len(new_method_hours),
            'å·®å¼‚': len(old_method_hours) - len(new_method_hours)
        }
        
        bars = ax5.bar(comparison_data.keys(), comparison_data.values(), 
                       color=['red', 'green', 'orange'], alpha=0.7)
        ax5.set_ylabel('ç§¯å‹æ—¶æ®µæ•°é‡')
        ax5.set_title('ä¼˜åŒ–å‰åç§¯å‹è¯†åˆ«å¯¹æ¯”')
        
        for bar, (key, value) in zip(bars, comparison_data.items()):
            height = bar.get_height()
            ax5.text(bar.get_x() + bar.get_width()/2., height + (0.1 if height >= 0 else -0.3),
                    f'{value}', ha='center', va='bottom' if height >= 0 else 'top', fontweight='bold')
        
        # 6. ç§¯å‹å¼ºåº¦åˆ†æ
        ax6 = axes[2, 1]
        final_hours = analysis_result['final_backlog_hours']
        if final_hours:
            intensities = [hourly_stats[h]['daily_mean'] for h in final_hours]
            ax6.bar(range(len(final_hours)), intensities, alpha=0.7, color='red')
            ax6.set_xticks(range(len(final_hours)))
            ax6.set_xticklabels([f'{h:02d}h' for h in final_hours])
            ax6.set_ylabel('å¹³å‡å»¶è¯¯èˆªç­æ•°')
            ax6.set_title('ç§¯å‹æ—¶æ®µå¼ºåº¦åˆ†æ')
        else:
            ax6.text(0.5, 0.5, 'æ— ç§¯å‹æ—¶æ®µ', ha='center', va='center', transform=ax6.transAxes, fontsize=14)
            ax6.set_title('ç§¯å‹æ—¶æ®µå¼ºåº¦åˆ†æ')
        
        plt.tight_layout()
        plt.savefig('ZGGGä¼˜åŒ–ç§¯å‹æ—¶æ®µåˆ†æ.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return fig

def main():
    """ä¸»å‡½æ•°"""
    print("=== ZGGGä¼˜åŒ–ç§¯å‹æ—¶æ®µè¯†åˆ«åˆ†æ ===")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = OptimizedBacklogAnalyzer(delay_threshold=4, base_backlog_threshold=10)
    
    # è½½å…¥æ•°æ®
    analyzer.load_real_data()
    
    # æ‰§è¡Œä¼˜åŒ–åˆ†æ
    analysis_result = analyzer.analyze_optimized_backlog()
    
    # å¯è§†åŒ–ç»“æœ
    analyzer.visualize_optimized_analysis(analysis_result)
    
    # è¾“å‡ºæ€»ç»“
    print(f"\n" + "="*60)
    print(f"                ç§¯å‹åˆ†æä¼˜åŒ–æ€»ç»“")
    print(f"="*60)
    print(f"âœ… åŸæ–¹æ³•è¯†åˆ«ç§¯å‹æ—¶æ®µ: 16ä¸ª (7:00-22:00è¿ç»­)")
    print(f"âœ… ä¼˜åŒ–æ–¹æ³•è¯†åˆ«ç§¯å‹æ—¶æ®µ: {len(analysis_result['final_backlog_hours'])}ä¸ª: {analysis_result['final_backlog_hours']}")
    print(f"âœ… è¿ç»­ç§¯å‹æ—¶æ®µæ•°: {len(analysis_result['continuous_periods'])}ä¸ª")
    
    if analysis_result['continuous_periods']:
        for i, period in enumerate(analysis_result['continuous_periods'], 1):
            start, end = period[0], period[-1]
            duration = len(period)
            print(f"   è¿ç»­ç§¯å‹{i}: {start:02d}:00-{end+1:02d}:00 (æŒç»­{duration}å°æ—¶)")
    
    print(f"\nğŸ¯ ä¼˜åŒ–ç­–ç•¥:")
    print(f"   â€¢ é‡‡ç”¨ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹æ›¿ä»£å›ºå®šé˜ˆå€¼")
    print(f"   â€¢ ç»“åˆæµé‡æ¿€å¢åˆ†æ")
    print(f"   â€¢ é™åˆ¶è¿ç»­ç§¯å‹æ—¶é•¿åœ¨1-5å°æ—¶èŒƒå›´")
    print(f"   â€¢ åŒºåˆ†æŒç»­ç¹å¿™ä¸çœŸæ­£ç§¯å‹")
    
    return analyzer, analysis_result

if __name__ == "__main__":
    analyzer, analysis_result = main()
